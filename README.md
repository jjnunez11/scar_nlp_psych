# Predicting Which Patients with Cancer Patients will see a Psychiatrist or Counsellor from their Initial Oncology Consultation Document Using Natural Language Processing

By John-Jose Nunez, on behalf of the co-authors

## Overview

For the manuscript "Predicting Which Cancer Patients Will See a Psychiatrist or Counsellor From Their Initial Oncology 
Consultation Document Using Natural Language Processing" submitted to Nature Communications.

This code base is the implementation of NLP methods to predict which cancer patients will see a psychiatrist, or a counsellor,
within the 12 months following their initial oncology consultation. The prediction is made using the documented generated by 
the medical or radiation oncologist at this initial visit. 

This code base is loosely based on the [Hedwig NLP repo](https://github.com/castorini/hedwig), but with extensive changes
and generally starting fresh due to the large changes in PyTorch 1.9.0 and especially torchtext 0.10.0. 

The code base is all written in Python 3.9, and besides install Python and libraries, does not 
requires the installation of any other programs. 

## System Requirements

### Operating System
This code was developed and ran on Windows Server 2012 R2 Standard, though we do not expect any problems
running this code on a Linux or MacOS system as Python is generally OS-agnostic. 

### Software dependencies and environment

For all python packages installed and their versions, please see the exported [conda enviroment export](./scar_nlp_env.yaml). 

Notable packages and their version numbers include:
- python 3.9.7
- pandas 1.3.3 
- numpy 1.21.2
- pytorch 1.9.0
- pytorch-lightning 1.4.9
- torchtext 0.10.0
- transformers 4.11.3

### Hardware requirements

We trained and ran our code on a shared GPU through a NVIDIA GRID V100D-16Q virtualization. Our driver was using CUDA 10.2, V10.2.89
Our code does support using CPU instead of GPU, though times to train and even evaluate may become prohibitive. 

Please consult [NVIDIA ](https://developer.nvidia.com/cuda-gpus#compute) and [PyTorch](https://pytorch.org/get-started/locally/) regarding
graphic card compatibility, as this varies depending on CUDA and version of PyTorch used. 

## Installation Guide

1. Ensure Python is installed, including required packages. 
2. Clone the Github repository, or extract a .zip, of the codebase. 
3. If using BERT as in our work, download the large language model [bert-based-uncased](https://huggingface.co/bert-base-uncased)
3. Run commands as per below. Directory and file paths can be specified with the command-line, use `-h` for help on arguments, e.g.

```
python -m models.cnn -h
```

We expect this to take no more than a few minutes, besides downloading the BERT files.  

## Demo

The [demo](./demo) folder contains toy data and the files needed to run our pretrained models. The toy data have some resemblance to what the data we used looks like. There are four differnt consults, repeated to make a bit more data, and with labels varied to show metric variety. 

If using BERT, please ensure the pretrained BERT files are downloaded, as above, and put into [correct folder for the demo](./demo/bert-base-uncased)

The [demo.bat](./demo.bat) file will evaluate one of each of our models on the toy data, for both psychiatry and counsellor predictions. 

Alternatively, you can run each as the following:

Evaluating previously trained models to predict seeing a psychiatrist within 12 months using toy data
```
python -m models.bow --target "dspln_PSYCHIATRY_12" --table "demo" --eval_only --model-file ".\results\final_results\dspln_PSYCHIATRY_12\BoW\BoW_20230220-1206_e0.pbz2" --data-dir ".\demo" --results-dir ".\demo"
python -m models.cnn  --target "dspln_PSYCHIATRY_12" --table "demo"  --eval_only --model-file ".\results\final_results\dspln_PSYCHIATRY_12\CNN\CNN_20230214-0927.pt" --data-dir ".\demo" --results-dir ".\demo"
python -m models.lstm --target "dspln_PSYCHIATRY_12" --table "demo"  --eval_only --model-file ".\results\final_results\dspln_PSYCHIATRY_12\LSTM\LSTM_20230214-1515.pt" --data-dir ".\demo" --results-dir ".\demo"
python -m models.bert --target "dspln_PSYCHIATRY_12" --table "demo" --eval_only --model-file ".\results\final_results\dspln_PSYCHIATRY_12\BERT\default\version_2\BERT--epoch=4_val_bal_val_bal=0.72.ckpt" --data-dir ".\demo" --results-dir ".\demo" --pretrained_dir ".\demo"
```
Evaluating previously trained models to predict seeing a counsellor within 12 months using toy data
```
python -m models.bow --target "dspln_SOCIALWORK_12" --table "demo" --eval_only --model-file ".\results\final_results\dspln_SOCIALWORK_12\BoW\BoW_20230220-1316_e0.pbz2" --data-dir ".\demo" --results-dir ".\demo"
python -m models.cnn  --target "dspln_SOCIALWORK_12" --table "demo"  --eval_only --model-file ".\results\final_results\dspln_SOCIALWORK_12\CNN\CNN_20230216-1157.pt" --data-dir ".\demo" --results-dir ".\demo"
python -m models.lstm --target "dspln_SOCIALWORK_12" --table "demo"  --eval_only --model-file ".\results\final_results\dspln_SOCIALWORK_12\LSTM\LSTM_20230216-1518.pt" --data-dir ".\demo" --results-dir ".\demo"
python -m models.bert --target "dspln_SOCIALWORK_12" --table "demo" --eval_only --model-file ".\results\final_results\dspln_SOCIALWORK_12\BERT\default\version_0\BERT--epoch=20_val_bal_val_bal=0.66.ckpt" --data-dir ".\demo" --results-dir ".\demo" --pretrained_dir ".\demo"
```
The expected outputs are located in `./demo/dspln_PSYCHIATRY_12/dspln_PSYCHIATRY_12_results.csv` and `./demo/dspln_SOCIALWORK_12/dspln_SOCIALWORK_12_results.csv` 

These should all run in a minute or two. 

Please see the next section regarding other arguments and parameters that can be changed. 

## Instructions for General Use

Models are ran as python modules. Arguments can be based through the command line. E.g.

```python -m cnn --target "dspln_PSYCHIATRY_12" --batch-size 16```

The possible arguments can be found in the `args.py` files located in `models`, and within each model's sub-folder.
Alternatively, you can use the `-h` command as above. 

See [models](./models) for the various deployed models. 

See [trainers](./trainers) for the trainers used to train the models

See [evaluators](./evaluators) for the code used to evaluate models

See [results](./results) for the final results and trained models

See [tables](./results) for some code used to generate tables as the raw data used for tables

For training the models on Windows, .bat files are provided that contain the command-line code,
as found in the [bats](./bats) folder. Sorry, I had to use Windows, as IT didn't support Linux on their virtualization.

To use BERT, please first download bert-base-uncased from [HuggingFace](https://huggingface.co/bert-base-uncased/tree/main)
The pytorch_model, config, and vocab files should be placed in a folder named bert-base-uncased, whose directory
in provided in the argument/default argument. If evaluating previously trained BERT models, you may need to change the backup
directory for the pretrained downloaded BERT models, located in `/models/bert/model.py` line 13. 

See the [viz](./viz) folder for jupyter notebooks used to visualize and understand the models.

Thank you for your interest in our work! Please don't hesitate to reach out - John-Jose, johnjose.nunez@bccancer.bc.ca

## Reproduction Instructions

To reproduce the final results presented in our work, you will need a copy of our raw data, and then can use the .bat
files within `/bats/tables/see_psych.bat` and `/bats/tables/see_counselling.bat` for the specific arguments provided. 

## Novel Multi-document Interpretation method

As part of revisions, we have developed and deployed a novel method to interpret neural networks across multiple 
documents that combines Layered Integrated Gradients with BERTopic. 

See the [multiligtopic](./multiligtopic) folder for the code for this method, again organized as a modular, with 
parameters/arguments available in `/multiligtopic/args.py`

It can be ran through the command line e.g.:

```python -m multiligtopic --criteria mean_above --cutoff 0.01 --device gpu```

Extracting the important sentences does take awhile. To save time, once the sentences are extract, the BERTopic
portion can be ran separately:

```python -m multiligtopic --load_sents --load_file ".\MultiLIGTopic\impt_sents_dspln_PSYCHIATRY_12_mean_above_0.01_49760.txt"```

To use OpenAI, you will need to put your api key in a file `/multiligtopic/openai_api_key.py`

## Licence

Copyright (C) 2023 John-Jose Nunez

This program is free software: you can redistribute it and/or modify it under the terms of the GNU Affero General Public 
License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later
version.

This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied
 warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU Affero General Public License for more details.

You should have received a copy of the GNU Affero General Public License along with this program.  
If not, see <https://www.gnu.org/licenses/>



