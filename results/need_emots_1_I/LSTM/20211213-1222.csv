epoch,acc,bal_acc,auc,prec,rec,f1,loss
0,0.538860103626943,0.5,0.5,0.538860103626943,0.538860103626943,0.538860103626943,0.6480284427341662
1,0.538860103626943,0.5,0.5,0.538860103626943,0.538860103626943,0.538860103626943,0.6477591928682829
2,0.538860103626943,0.5,0.5,0.538860103626943,0.538860103626943,0.538860103626943,0.647605930504046
3,0.538860103626943,0.5,0.5,0.538860103626943,0.538860103626943,0.538860103626943,0.6474687174746865
4,0.538860103626943,0.5,0.5,0.538860103626943,0.538860103626943,0.538860103626943,0.6472867193974947
5,0.538860103626943,0.5,0.5,0.538860103626943,0.538860103626943,0.538860103626943,0.647001934678931

Run Arguments:
cuda: True
gpu: 0
cuda_block: False
epochs: 100
batch_size: 32
seed: 3435
patience: 5
log_every: 10
imbalance_fix: loss_weight
data_dir: C:\Users\jjnunez\PycharmProjects\scar_nlp_data\data
results_dir: C:\Users\jjnunez\PycharmProjects\scar_nlp\results
data_version: ppv4
target: need_emots_1_I
dataset: SCAR
debug: False
bidirectional: False
num_layers: 2
hidden_dim: 128
mode: rand
words_dim: 300
embed_dim: 300
weight_decay: 0
dropout: 0.5
lr: 0.0001
pretrained_dir: C:\Users\jjnunez\PycharmProjects\hedwig-data\embeddings\word2vec
pretrained_file: GoogleNews-vectors-negative300.txt
results_path: results\reg_lstm
device: cuda:0
