epoch,acc,bal_acc,auc,prec,rec,f1,loss,epoch
0,0.4328324794769287,0.5001911520957947,0.5100705623626709,0.5762711763381958,0.013396374881267548,0.02618405781686306,0.0,0.0
1,0.5337519645690918,0.539615273475647,0.5557584762573242,0.6111379861831665,0.49724188446998596,0.5483380556106567,0.0,1.0
2,0.5303879976272583,0.554503858089447,0.5903855562210083,0.6493943333625793,0.3802206516265869,0.4796222746372223,0.0,2.0
3,0.5768109560012817,0.5830718278884888,0.6137844324111938,0.6565656661987305,0.5378250479698181,0.5912930369377136,0.0,3.0
4,0.5790535807609558,0.587066650390625,0.6188194155693054,0.663209855556488,0.5291568040847778,0.5886478424072266,0.0,4.0
5,0.5779322981834412,0.5860816240310669,0.6238688826560974,0.6623762249946594,0.5271867513656616,0.587099552154541,0.0,5.0
6,0.5898183584213257,0.5908281803131104,0.631705641746521,0.6573457717895508,0.5835303664207458,0.6182425022125244,0.0,6.0
7,0.5911639332771301,0.5937819480895996,0.636223554611206,0.6622787117958069,0.5748621225357056,0.615481972694397,0.0,7.0
8,0.5877999663352966,0.5958888530731201,0.6378359794616699,0.672583818435669,0.5374310612678528,0.5974594950675964,0.0,8.0
9,0.5929580330848694,0.6005465388298035,0.6417641639709473,0.67659991979599,0.545705258846283,0.6041439175605774,0.0,9.0
10,0.6088809370994568,0.6008031368255615,0.6456546783447266,0.6555642485618591,0.6591804623603821,0.6573673486709595,0.0,10.0
11,0.5931823253631592,0.6039073467254639,0.6414295434951782,0.685831606388092,0.5263987183570862,0.5956308841705322,0.0,11.0
12,0.5925095081329346,0.6011649370193481,0.6446026563644409,0.6790859699249268,0.5386130809783936,0.6007471084594727,0.0,12.0
13,0.6095536947250366,0.5989264249801636,0.6438716650009155,0.6513482928276062,0.675728976726532,0.663314700126648,0.0,13.0
14,0.5642520785331726,0.5919713377952576,0.6394083499908447,0.7135679125785828,0.39164695143699646,0.5057237148284912,0.0,14.0
15,0.5687373876571655,0.5941396951675415,0.6384837031364441,0.7093260884284973,0.4105595052242279,0.520089864730835,0.0,15.0
16,0.5969948172569275,0.5979548692703247,0.6353814601898193,0.6640106439590454,0.5910165309906006,0.625390887260437,0.0,16.0

Run Arguments:
cuda: True
gpu: 0
cuda_block: False
epochs: 50
batch_size: 8
seed: 3435
patience: 5
log_every: 10
imbalance_fix: loss_weight
data_dir: C:\Users\jjnunez\PycharmProjects\hedwig-data\datasets
results_dir: C:\Users\jjnunez\PycharmProjects\scar_nlp\results
data_version: ppv3
target: emots
debug: False
dataset: SCAR
max_tokens: 512
lr: 0.0001
weight_decay: 0
pretrained_dir: C:\Users\jjnunez\PycharmProjects\hedwig-data\models
pretrained_file: biobert_pretrain_output_all_notes_150000
device: cuda:0
