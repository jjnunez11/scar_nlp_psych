epoch,acc,bal_acc,auc,prec,rec,f1,loss,epoch
0,0.2363758683204651,0.5,0.45735859870910645,0.2363758683204651,1.0,0.38236895203590393,0.0,0.0
1,0.44853106141090393,0.5255843997001648,0.5304946899414062,0.2509748339653015,0.6717267632484436,0.3654193580150604,0.0,1.0
2,0.2783135175704956,0.5127202868461609,0.5865570306777954,0.24127213656902313,0.9573054909706116,0.3854087293148041,0.0,2.0
3,0.4783583879470825,0.5732829570770264,0.6135318279266357,0.27762237191200256,0.7533206939697266,0.4057230055332184,0.0,3.0
4,0.5678403377532959,0.5889654755592346,0.6340345144271851,0.30150067806243896,0.6290322542190552,0.4076237380504608,0.0,4.0
5,0.5362188816070557,0.6056002378463745,0.6524442434310913,0.302570104598999,0.7371916770935059,0.4290447235107422,0.0,5.0
6,0.5893698334693909,0.6246800422668457,0.673882007598877,0.3261744976043701,0.6916508674621582,0.44329583644866943,0.0,6.0
7,0.5909397006034851,0.6391371488571167,0.6890572905540466,0.3333333432674408,0.7305502891540527,0.457788348197937,0.0,7.0
8,0.5559542775154114,0.6358820199966431,0.6967258453369141,0.3209590017795563,0.7874763011932373,0.45604392886161804,0.0,8.0
9,0.6129177212715149,0.6486146450042725,0.7049795985221863,0.34601283073425293,0.7163187861442566,0.4666254222393036,0.0,9.0
10,0.5606638193130493,0.6461716294288635,0.7074984908103943,0.32656189799308777,0.8083491325378418,0.4651924669742584,0.0,10.0
11,0.602152943611145,0.654995322227478,0.7136619091033936,0.3442906439304352,0.7552182078361511,0.47296491265296936,0.0,11.0
12,0.6667414307594299,0.6651871204376221,0.71832674741745,0.3818380832672119,0.6622390747070312,0.48438581824302673,0.0,12.0
13,0.630186140537262,0.6645070314407349,0.7197306752204895,0.3605250418186188,0.7296015620231628,0.4825855493545532,0.0,13.0
14,0.700605571269989,0.6513309478759766,0.7192996144294739,0.40356898307800293,0.5578747391700745,0.46833929419517517,0.0,14.0
15,0.6566494703292847,0.6611995100975037,0.7210609912872314,0.3737427294254303,0.6698291897773743,0.4797825515270233,0.0,15.0
16,0.7102489471435547,0.650111734867096,0.722357988357544,0.41301169991493225,0.5360531210899353,0.4665565490722656,0.0,16.0
17,0.6548553705215454,0.651181161403656,0.7133902907371521,0.3684210479259491,0.644212543964386,0.46876081824302673,0.0,17.0

Run Arguments:
cuda: True
gpu: 0
cuda_block: False
epochs: 50
batch_size: 8
seed: 3435
patience: 5
log_every: 10
imbalance_fix: loss_weight
data_dir: C:\Users\jjnunez\PycharmProjects\scar_nlp_data\data
results_dir: C:\Users\jjnunez\PycharmProjects\scar_nlp\results
data_version: ppv3
target: dspln_SOCIALWORK_0
debug: False
dataset: SCAR
max_tokens: 512
lr: 0.0001
weight_decay: 0
pretrained_dir: C:\Users\jjnunez\PycharmProjects\hedwig-data\models
pretrained_file: bert-base-uncased
device: cuda:0
