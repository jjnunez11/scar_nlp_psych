epoch,acc,bal_acc,auc,prec,rec,spec,f1,loss,ppv,npv,tp,fp,tn,fn
0,0.7396888136863708,0.7124180793762207,0.7858514785766602,0.42730721831321716,0.6650270819664001,0.759809136390686,0.5203002095222473,0.889899492263794,0.427307206068268,0.8938094495555902,1352.0,1812.0,5732.0,681.0

Run Arguments:
cuda: True
gpu: 0
cuda_block: False
epochs: 100
seed: 3435
patience: 5
monitor_metric: bal_acc
log_every: 10
imbalance_fix: loss_weight
data_dir: C:\Users\jjnunez\PycharmProjects\scar_nlp_data\data
results_dir: C:\Users\jjnunez\PycharmProjects\scar_nlp_psych\results
data_version: ppv4
target: dspln_SOCIALWORK_12
table: see_counselling
table_extra: 
dataset: SCAR
debug: False
eval_only: False
model_file: None
bidirectional: True
num_layers: 1
hidden_dim: 512
mode: rand
words_dim: 300
embed_dim: 300
weight_decay: 0
dropout: 0.2
lr: 0.0005
batch_size: 16
embed_droprate: 0.1
wdrop: 0.01
pretrained_dir: C:\Users\jjnunez\PycharmProjects\hedwig-data\embeddings\word2vec
pretrained_file: GoogleNews-vectors-negative300.txt
results_path: results\reg_lstm
device: cuda:0
target_classes: 1
vocab_size: 22338
run_name: LSTM_20230225-2140
results_dir_target: C:\Users\jjnunez\PycharmProjects\scar_nlp_psych\results\dspln_SOCIALWORK_12
results_dir_model: C:\Users\jjnunez\PycharmProjects\scar_nlp_psych\results\dspln_SOCIALWORK_12\LSTM
