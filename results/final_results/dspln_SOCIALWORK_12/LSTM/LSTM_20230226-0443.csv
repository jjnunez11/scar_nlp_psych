epoch,acc,bal_acc,auc,prec,rec,spec,f1,loss,ppv,npv,tp,fp,tn,fn
0,0.7122272253036499,0.7055872082710266,0.7795517444610596,0.39802539348602295,0.6940482258796692,0.717126190662384,0.5059160590171814,0.8960205316543579,0.3980253878702398,0.8968832891246684,1411.0,2134.0,5410.0,622.0

Run Arguments:
cuda: True
gpu: 0
cuda_block: False
epochs: 100
seed: 3435
patience: 5
monitor_metric: bal_acc
log_every: 10
imbalance_fix: loss_weight
data_dir: C:\Users\jjnunez\PycharmProjects\scar_nlp_data\data
results_dir: C:\Users\jjnunez\PycharmProjects\scar_nlp_psych\results
data_version: ppv4
target: dspln_SOCIALWORK_12
table: see_counselling
table_extra: 
dataset: SCAR
debug: False
eval_only: False
model_file: None
bidirectional: True
num_layers: 1
hidden_dim: 512
mode: rand
words_dim: 300
embed_dim: 300
weight_decay: 0
dropout: 0.2
lr: 0.0005
batch_size: 16
embed_droprate: 0.1
wdrop: 0.01
pretrained_dir: C:\Users\jjnunez\PycharmProjects\hedwig-data\embeddings\word2vec
pretrained_file: GoogleNews-vectors-negative300.txt
results_path: results\reg_lstm
device: cuda:0
target_classes: 1
vocab_size: 22338
run_name: LSTM_20230226-0443
results_dir_target: C:\Users\jjnunez\PycharmProjects\scar_nlp_psych\results\dspln_SOCIALWORK_12
results_dir_model: C:\Users\jjnunez\PycharmProjects\scar_nlp_psych\results\dspln_SOCIALWORK_12\LSTM
