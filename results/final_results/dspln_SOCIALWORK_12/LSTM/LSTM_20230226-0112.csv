epoch,acc,bal_acc,auc,prec,rec,spec,f1,loss,ppv,npv,tp,fp,tn,fn
0,0.7264279127120972,0.7101093530654907,0.78219074010849,0.4126228094100952,0.6817511320114136,0.7384676337242126,0.5140949487686157,0.8932561278343201,0.41262280440607324,0.8959472499195883,1386.0,1973.0,5571.0,647.0

Run Arguments:
cuda: True
gpu: 0
cuda_block: False
epochs: 100
seed: 3435
patience: 5
monitor_metric: bal_acc
log_every: 10
imbalance_fix: loss_weight
data_dir: C:\Users\jjnunez\PycharmProjects\scar_nlp_data\data
results_dir: C:\Users\jjnunez\PycharmProjects\scar_nlp_psych\results
data_version: ppv4
target: dspln_SOCIALWORK_12
table: see_counselling
table_extra: 
dataset: SCAR
debug: False
eval_only: False
model_file: None
bidirectional: True
num_layers: 1
hidden_dim: 512
mode: rand
words_dim: 300
embed_dim: 300
weight_decay: 0
dropout: 0.2
lr: 0.0005
batch_size: 16
embed_droprate: 0.1
wdrop: 0.01
pretrained_dir: C:\Users\jjnunez\PycharmProjects\hedwig-data\embeddings\word2vec
pretrained_file: GoogleNews-vectors-negative300.txt
results_path: results\reg_lstm
device: cuda:0
target_classes: 1
vocab_size: 22338
run_name: LSTM_20230226-0112
results_dir_target: C:\Users\jjnunez\PycharmProjects\scar_nlp_psych\results\dspln_SOCIALWORK_12
results_dir_model: C:\Users\jjnunez\PycharmProjects\scar_nlp_psych\results\dspln_SOCIALWORK_12\LSTM
